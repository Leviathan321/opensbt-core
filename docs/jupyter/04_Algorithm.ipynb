{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Algorithm Integration\n",
    "\n",
    "In this tutorial we show how to integrate a search algorithm into OpenSBT to use it for testing.\n",
    "To integrate a search algorithm we need to create a new class subclassing the [`Optimizer`](https://git.fortiss.org/opensbt/opensbt-core/-/blob/main/algorithm/optimizer.py) class. There are different options available depending on whether the algorithm exists in pymoo already or not. We show in the following in detail for each of the cases how the integration is done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Algorithm exists in Pymoo\n",
    "\n",
    "If the search algorithm exists in `pymoo`, we can instantiate it in the `__init__` method and assign it to the `algorithm` variable. Existing algorithms in pymoo can be explored [here](https://pymoo.org/algorithms/index.html).\n",
    "\n",
    "In this example we want to integrate the Non-dominated Sorting Genetic Algorithm (NSGA-II) algorithm wich already exists in [pymoo](https://github.com/anyoptimization/pymoo/blob/main/pymoo/algorithms/moo/nsga2.py#L84) into OpenSBT. \n",
    "\n",
    "The final NSGA-II related Optimizer class looks as follows:\n",
    "\n",
    "```python\n",
    "from pymoo.core.problem import Problem\n",
    "from pymoo.termination import get_termination\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from opensbt.algorithm.optimizer import Optimizer\n",
    "from opensbt.experiment.search_configuration import SearchConfiguration\n",
    "\n",
    "class Nsga2Optimizer(Optimizer):\n",
    "\n",
    "    # This name is used in the output plots \n",
    "    algorithm_name = \"NSGA-II\"\n",
    "\n",
    "    def __init__(self,\n",
    "                problem: Problem,\n",
    "                config: SearchConfiguration):\n",
    "\n",
    "        # Default code\n",
    "        self.config = config\n",
    "        self.problem = problem\n",
    "        self.res = None\n",
    "\n",
    "        # The parameters dict is forwarded to the output and is algorithm specific;\n",
    "        # It contains information about the algorithm configuration\n",
    "        self.parameters = {\n",
    "            \"Population size\" : str(config.population_size),\n",
    "            \"Max number of generations\" : str(config.n_generations),\n",
    "        }\n",
    "\n",
    "        # Initialize pymoo algorithm\n",
    "        self.algorithm = NSGA2(\n",
    "            pop_size=config.population_size,\n",
    "        )\n",
    "\n",
    "        ''' Prioritize max search time over set maximal number of generations'''\n",
    "        if config.maximal_execution_time is not None:\n",
    "            self.termination = get_termination(\"time\", config.maximal_execution_time)\n",
    "        else:\n",
    "            self.termination = get_termination(\"n_gen\", config.n_generations)\n",
    "\n",
    "        self.save_history = True\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Algorithm does not exist in Pymoo\n",
    "\n",
    "If the algorithm does not exist in pymoo, we can override `run` and implement the algorithm into the run method. The type of the returned object should be a `SimulationResult`. As an example, we have implemented the machine learning- based algorithm NSGA-II-DT algorithm from [Abdessalam et al.](https://ieeexplore.ieee.org/document/8453180) which does not exist in Pymoo.\n",
    "\n",
    "**Note: A more convenient way to integrate a individualized algorithm is by sublassing the [`Algorithm`](https://github.com/anyoptimization/pymoo/blob/main/pymoo/core/algorithm.py) class from pymoo and using the first option for the integration.** \n",
    "\n",
    "We see below an excerpt of the implementation of NSGAII-DT where we have performed the steps without creating a new `Algorithm` class. We have ommited algorithm specific dependencies. The complete implementation is available [here](https://git.fortiss.org/opensbt/opensbt-core/-/blob/main/opensbt/algorithm/nsga2_optimizer.py).\n",
    "\n",
    "Note that the implementation of the algorithm functionality starts from 104ff. \n",
    "\n",
    "```python\n",
    "from pymoo.core.problem import Problem\n",
    "from pymoo.termination import get_termination\n",
    "from opensbt.algorithm.optimizer import Optimizer\n",
    "from opensbt.experiment.search_configuration import SearchConfiguration\n",
    "\n",
    "class NsgaIIDTOptimizer(Optimizer):\n",
    "\n",
    "    algorithm_name = \"NSGAII-DT\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 problem: Problem,\n",
    "                 config: SearchConfiguration):\n",
    "\n",
    "        self.problem = problem\n",
    "        self.config = config\n",
    "        self.res = None\n",
    "\n",
    "        self.parameters = {\n",
    "            'Number of maximal tree generations': str(config.max_tree_iterations),\n",
    "            \"Population size\": str(config.population_size),\n",
    "            \"Number of generations\": str(config.inner_num_gen),\n",
    "            \"Number of offsprings\": str(config.num_offsprings),\n",
    "            \"Crossover probability\": str(config.prob_crossover),\n",
    "            \"Crossover eta\": str(config.eta_crossover),\n",
    "            \"Mutation probability\": str(config.prob_mutation),\n",
    "            \"Mutation eta\": str(config.eta_mutation)\n",
    "        }\n",
    "        \n",
    "    ''' Overriding run of optimizer class to implement specific search approach'''\n",
    "    def run(self) -> SimulationResult:\n",
    "        \n",
    "        ''' Define your algorithm below '''\n",
    "        problem = self.problem\n",
    "        config = self.config\n",
    "\n",
    "        population_size = config.population_size\n",
    "        maximal_execution_time = config.maximal_execution_time\n",
    "        max_tree_iterations = config.max_tree_iterations\n",
    "        num_offsprings = config.num_offsprings\n",
    "        prob_crossover = config.prob_crossover\n",
    "        eta_crossover = config.eta_crossover\n",
    "        prob_mutation = config.prob_mutation\n",
    "        eta_mutation = config.eta_mutation\n",
    "        inner_num_gen = config.inner_num_gen\n",
    "\n",
    "        '''Output variables'''\n",
    "        all_population = Population()\n",
    "        best_population = Population()\n",
    "        best_population_unranked = Population()\n",
    "\n",
    "        '''Initial conditions (initial region)'''\n",
    "        xl = problem.xl\n",
    "        xu = problem.xu\n",
    "\n",
    "        sampling = LHS()  \n",
    "        initial_population = sampling(problem, population_size)\n",
    "        hist_holder = []\n",
    "\n",
    "        '''Parameters of the algorithm'''\n",
    "        if prob_mutation is None:\n",
    "            prob_mutation = 1 / problem.n_var\n",
    "\n",
    "        '''Parameter for evaluation'''\n",
    "        if maximal_execution_time is not None:\n",
    "            _maximal_execution_time = convert_pymoo_time_to_seconds(\n",
    "                maximal_execution_time)\n",
    "            max_tree_iterations = sys.maxsize\n",
    "            log.info(\"Search is constrained by maximal execution time\")\n",
    "        elif max_tree_iterations is not None:\n",
    "            _maximal_execution_time = sys.maxsize\n",
    "            log.info(\"Search is constrained by maximal number of tree generations\")\n",
    "        else:\n",
    "            log.info(\"Parameters are not correctly set, cannot start search.\")\n",
    "            sys.exit()\n",
    "\n",
    "        ''' Computation start '''\n",
    "        start_time = time.time()\n",
    "        evaluate_individuals(initial_population, problem)\n",
    "        initial_region = decision_tree.Region(xl, xu, initial_population)\n",
    "        critical_regions = [initial_region]\n",
    "        hist_holder = []\n",
    "\n",
    "        # inner_algorithm is a template for an algorithm object that is stored for every generation\n",
    "        inner_algorithm = NSGA2(\n",
    "            pop_size=None,\n",
    "            n_offsprings=None,\n",
    "            sampling=None,\n",
    "            crossover=SBX(prob=prob_crossover, eta=eta_crossover),\n",
    "            mutation=PM(prob=prob_mutation, eta=eta_mutation),\n",
    "            eliminate_duplicates=True)\n",
    "\n",
    "        # Implementation of the NSGA-II-DT is below\n",
    "        tree_iteration = 0\n",
    "        n_func_evals = 0\n",
    "        while n_func_evals < config.n_func_evals_lim:\n",
    "            \n",
    "            # extend the history by one generation\n",
    "            hist_holder.extend([inner_algorithm] * inner_num_gen)\n",
    "\n",
    "            log.info(f\"running iteration {tree_iteration}\")\n",
    "            for critical_region in critical_regions:\n",
    "                    \n",
    "                sub_problem = problem\n",
    "\n",
    "                if prob_mutation == None:\n",
    "                    prob_mutation = 1 / problem.n_var\n",
    "\n",
    "                nd_individuals_region = calc_nondominated_individuals(critical_region.population)\n",
    "                initial_population = Population(\n",
    "                    individuals=nd_individuals_region)\n",
    "                pop_size = len(initial_population)\n",
    "\n",
    "                algorithm = NSGA2(\n",
    "                    pop_size=pop_size,\n",
    "                    n_offsprings=num_offsprings,\n",
    "                    sampling=initial_population,\n",
    "                    crossover=SBX(prob=prob_crossover, eta=eta_crossover),\n",
    "                    mutation=PM(prob=prob_mutation, eta=eta_mutation),\n",
    "                    eliminate_duplicates=True)\n",
    "\n",
    "                termination = get_termination(\"n_gen\", inner_num_gen)\n",
    "\n",
    "                res = minimize(sub_problem,\n",
    "                               algorithm,\n",
    "                               termination,\n",
    "                               seed=1,\n",
    "                               save_history=True,\n",
    "                               verbose=True)\n",
    "\n",
    "                n_func_evals += res.history[-1].evaluator.n_eval\n",
    "\n",
    "                self.update_history(res, hist_holder, tree_iteration, inner_num_gen, inner_algorithm)\n",
    "\n",
    "                hist = res.history\n",
    "\n",
    "                # hist[i] is an object of <class 'pymoo.algorithms.moo.nsga2.NSGA2'>\n",
    "                best_population_unranked = Population.merge(\n",
    "                    best_population, res.opt)\n",
    "                best_population = get_nondominated_population(\n",
    "                    best_population_unranked)\n",
    "                for generation in hist:\n",
    "                    all_population = Population.merge(\n",
    "                        all_population, generation.pop)\n",
    "\n",
    "            initial_region.population = best_population\n",
    "\n",
    "            regions = decision_tree.generate_critical_regions(\n",
    "                all_population, problem, save_folder=None)\n",
    "            critical_regions = [\n",
    "                region for region in regions if region.is_critical]\n",
    "            if not critical_regions:\n",
    "                critical_regions = [initial_region]\n",
    "            tree_iteration += 1\n",
    "\n",
    "        execution_time = time.time() - start_time\n",
    "        \n",
    "        # Create SimulationResult object from all information gathered from search execution\n",
    "        result = self.create_result(problem, hist_holder, inner_algorithm, execution_time)\n",
    "        self.res = result\n",
    "        return result\n",
    "   \n",
    "    def _update_history(self, res, hist_holder, tree_iteration, inner_num_gen, inner_algorithm):\n",
    "        for i in range(inner_num_gen):\n",
    "            pop = Population.merge(\n",
    "                hist_holder[tree_iteration * inner_num_gen + i].pop, res.history[i].pop)\n",
    "            # copy a template of the inner algorithm, and then modify its population and other properties\n",
    "            algo = copy.deepcopy(inner_algorithm)\n",
    "            algo.pop = pop\n",
    "            opt_pop = Population(\n",
    "                individuals=calc_nondominated_individuals(pop))\n",
    "            algo.opt = opt_pop\n",
    "            hist_holder[tree_iteration * inner_num_gen + i] = algo\n",
    "\n",
    "    ''' Method allows us to store results in pymoos results structure to be passed to visualizer,analyser of OpenSBT '''\n",
    "    def _create_result(self, problem, hist_holder, inner_algorithm, execution_time):\n",
    "        I = 0\n",
    "        for algo in hist_holder:\n",
    "            I += len(algo.pop)\n",
    "            algo.evaluator.n_eval = I\n",
    "            algo.start_time = 0\n",
    "            algo.problem = problem\n",
    "            algo.result()\n",
    "\n",
    "        res_holder = SimulationResult()\n",
    "        res_holder.algorithm = inner_algorithm\n",
    "        res_holder.algorithm.evaluator.n_eval = I\n",
    "        res_holder.problem = problem\n",
    "        res_holder.algorithm.problem = problem\n",
    "        res_holder.history = hist_holder\n",
    "        res_holder.exec_time = execution_time\n",
    "\n",
    "        # calculate total optimal population using individuals from all iterations\n",
    "        opt_all = Population()\n",
    "        for algo in hist_holder:\n",
    "            opt_all = Population.merge(opt_all, algo.pop)\n",
    "        opt_all_nds = get_nondominated_population(opt_all)\n",
    "        res_holder.opt = opt_all_nds\n",
    "\n",
    "        return res_holder\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register Algorithm for Terminal Usage\n",
    "\n",
    "If we want to make the algorithm accessable via terminal, we need first to register the algorithm in ```algorithm.py```.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from enum import Enum\n",
    "\n",
    "# Define here all available algorithms to be triggered via number in -a flag.\n",
    "class AlgorithmType(Enum):\n",
    "    NSGAII = 1          \n",
    "    PSO = 2 \n",
    "    PS_RAND= 3 \n",
    "    PS_GRID = 4 \n",
    "    PS_FPS = 5\n",
    "    NSGAII_DT = 6 # NSGAII-DT is registered here with the number 6\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Then we can add the new algorithm to `run.py` to the switch case block as below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python \n",
    "\n",
    "from opensbt.algorithm.nsga2dt_optimizer import NsgaIIDTOptimizer\n",
    "from opensbt.algorithm.algorithm import AlgorithmType\n",
    "\n",
    "# [...]\n",
    "\n",
    "if (..) # existing conditions not mentioned\n",
    "    pass\n",
    "elif (algorithm == AlgorithmType.NSGAII_DT):\n",
    "    \n",
    "    optimizer = NsgaIIDTOptimizer(\n",
    "                        problem=problem,\n",
    "                        config=config)\n",
    "\n",
    "    res = optimizer.run()\n",
    "    \n",
    "    res.write_results(results_folder=results_folder, \n",
    "                      params = optimizer.parameters)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm can then be invoked using -a flag for a defined experiment (here: on our toy example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lev\\Documents\\fortiss\\projects\\testing\\open-sbt\\opensbt-core\\docs\\jupyter\\opensbt-core\n"
     ]
    }
   ],
   "source": [
    "cd opensbt-core/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run.py -e 5 -a 6 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When all results have been written, we can inspect the outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "exp_folder = os.getcwd() + f\"/results/DummySimulatorProblem/NSGA2/\"\n",
    "paths = sorted(Path(exp_folder).iterdir(), key=os.path.getmtime)\n",
    "results_path = str(paths[-1])\n",
    "\n",
    "df = pd.read_csv(f'{results_path}/all_critical_testcases.csv')\n",
    "\n",
    "from IPython.display import Image\n",
    "import os\n",
    "n = 4 # show max n images\n",
    "folder_gifs = results_path + os.sep + \"gif\"\n",
    "i = 0\n",
    "for f in os.listdir(folder_gifs):\n",
    "    fpath = folder_gifs + os.sep + f\n",
    "    if os.path.isfile(fpath) and i < n:\n",
    "      img = Image(open(fpath,'rb').read(), width=300, height=300)\n",
    "      display(img)\n",
    "      i = i+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "936ca7e20bca62b66c7c316e70494dc6b833065bb3866688df5c5758a2e02a05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
